---
layout: post
title: "Truth or Error? Towards systematic analysis of factual errors in abstractive summaries"
date: 2020-11-16 15:00:00+0200
inline: false
---

Our paper **"Truth or Error? Towards systematic analysis of factual errors in abstractive summaries"**
is accepted for publication at the [Eval4NLP](https://nlpevaluation2020.github.io/) workshop co-located
with The 2020 Conference on Empirical Methods in Natural Language Processing ([EMNLP](https://2020.emnlp.org/))

**Abstract**

This paper presents a typology of errors produced by automatic summarization systems.
The typology was created by manually analyzing the output of four recent neural summarization systems.
Our work is motivated by the growing awareness of the need for better summary evaluation methods that go beyond conventional overlap-based metrics.
Our typology is structured into two dimensions.
First, the Mapping Dimension describes surface-level errors and provides insight into word-sequence transformation issues.
Second, the Meaning Dimension describes issues related to interpretation and provides insight into breakdowns in truth, i.e., factual faithfulness to the original text.
Comparative analysis revealed that two neural summarization systems leveraging pre-trained models have an advantage in decreasing grammaticality errors, but not necessarily factual errors.
We also discuss the importance of ensuring that summary length and abstractiveness do not interfere with evaluating summary quality.
